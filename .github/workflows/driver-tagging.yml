name: "Driver Tagging (Python)"

on:
  workflow_dispatch: # Manual trigger
  workflow_run:
    workflows: ["Update LOLDrivers Data"]
    types:
      - completed
    branches:
      - main

permissions:
  contents: write
  actions: read

jobs:
  check_prerequisites:
    runs-on: ubuntu-latest
    outputs:
      should_run: ${{ steps.check.outputs.should_run }}
    steps:
    - name: Check if workflow should run
      id: check
      run: |
        echo "Event: ${{ github.event_name }}"
        
        if [ "${{ github.event_name }}" != "workflow_run" ]; then
          echo "Manual trigger - running"
          echo "should_run=true" >> $GITHUB_OUTPUT
        elif [ "${{ github.event.workflow_run.conclusion }}" = "success" ]; then
          echo "Previous workflow successful - running"
          echo "should_run=true" >> $GITHUB_OUTPUT
        else
          echo "Previous workflow failed - skipping"
          echo "should_run=false" >> $GITHUB_OUTPUT
        fi

  download_blocklist:
    runs-on: ubuntu-latest
    needs: check_prerequisites
    if: needs.check_prerequisites.outputs.should_run == 'true'
    outputs:
      hash_changed: ${{ steps.download.outputs.hash_changed }}
    steps:
    - name: Checkout
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Download and check Microsoft HVCI blocklist
      id: download
      run: |
        echo "Downloading Microsoft HVCI Vulnerable Driver Blocklist..."
        
        # Download blocklist
        wget -O VulnerableDriverBlockList.zip "https://aka.ms/VulnerableDriverBlockList"
        
        # Calculate current hash
        current_hash=$(sha256sum VulnerableDriverBlockList.zip | cut -d' ' -f1)
        echo "Current hash: $current_hash"
        
        # Check previous hash
        if [ -f "data/blocklist-hash.txt" ]; then
          # Look for a valid hash (64 hex characters)
          if grep -q "^[A-Fa-f0-9]\{64\}$" data/blocklist-hash.txt; then
            previous_hash=$(grep "^[A-Fa-f0-9]\{64\}$" data/blocklist-hash.txt | head -1)
            echo "Previous hash: $previous_hash"
            
            if [ "$current_hash" = "$previous_hash" ]; then
              echo "Hash unchanged - skipping analysis"
              echo "hash_changed=false" >> $GITHUB_OUTPUT
              exit 0
            fi
          else
            echo "No valid hash found in blocklist-hash.txt - proceeding with first run"
          fi
        else
          echo "No hash file found - proceeding with first run"
        fi
        
        echo "Hash changed or first run - proceeding"
        echo "$current_hash" > data/blocklist-hash.txt
        echo "hash_changed=true" >> $GITHUB_OUTPUT
        
    - name: Upload blocklist and hash
      if: steps.download.outputs.hash_changed == 'true'
      uses: actions/upload-artifact@v4
      with:
        name: blocklist
        path: |
          VulnerableDriverBlockList.zip
          data/blocklist-hash.txt

  analyze_hvci:
    runs-on: ubuntu-latest
    needs: download_blocklist
    if: needs.download_blocklist.outputs.hash_changed == 'true'
    steps:
    - name: Checkout
      uses: actions/checkout@v4
      
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        pip install lxml requests
        
    - name: Download blocklist
      uses: actions/download-artifact@v4
      with:
        name: blocklist
        
    - name: Analyze HVCI policy
      run: |
        cat > analyze_hvci.py << 'EOF'
        #!/usr/bin/env python3
        import json
        import zipfile
        import xml.etree.ElementTree as ET
        import re
        import csv
        from pathlib import Path
        
        def extract_blocklist():
            """Extract the ZIP and find the XML policy file"""
            with zipfile.ZipFile('VulnerableDriverBlockList.zip', 'r') as zip_ref:
                zip_ref.extractall('blocklist')
            
            # Find XML files
            xml_files = list(Path('blocklist').rglob('*.xml'))
            print(f"Found {len(xml_files)} XML files")
            
            # Look for SiPolicy XML
            target_xml = None
            for xml_file in xml_files:
                if 'SiPolicy' in xml_file.name:
                    target_xml = xml_file
                    break
            
            if not target_xml and xml_files:
                target_xml = xml_files[0]
                
            if not target_xml:
                raise FileNotFoundError("No XML policy file found")
                
            print(f"Using XML file: {target_xml}")
            return target_xml
        
        def parse_hvci_policy(xml_file):
            """Parse HVCI policy and extract blocked items"""
            tree = ET.parse(xml_file)
            root = tree.getroot()
            
            # Find namespace
            ns = {'si': 'urn:schemas-microsoft-com:sipolicy'}
            if root.tag.startswith('{'):
                ns_uri = root.tag.split('}')[0][1:]
                ns = {'si': ns_uri}
            
            blocked_hashes = {}
            blocked_signers = {}
            blocked_filenames = {}
            
            # Extract denied file rules
            for deny_rule in root.findall('.//si:Deny', ns):
                # Hash rules
                hash_attr = deny_rule.get('Hash')
                if hash_attr:
                    clean_hash = re.sub(r'[^A-F0-9]', '', hash_attr.upper())
                    if len(clean_hash) in [32, 40, 64]:  # MD5, SHA1, SHA256
                        hash_type = {32: 'MD5', 40: 'SHA1', 64: 'SHA256'}[len(clean_hash)]
                        blocked_hashes[clean_hash] = hash_type
                
                # Filename rules
                filename = deny_rule.get('FileName')
                if filename:
                    max_version = deny_rule.get('MaximumFileVersion')
                    blocked_filenames[filename] = max_version
            
            # Extract signers
            for signer in root.findall('.//si:Signer', ns):
                cert_root = signer.find('si:CertRoot', ns)
                if cert_root is not None:
                    tbs_hash = cert_root.get('Value', '').lower()
                    if tbs_hash:
                        blocked_signers[tbs_hash] = signer.get('Name', 'Unknown')
            
            print(f"Extracted: {len(blocked_hashes)} hashes, {len(blocked_signers)} signers, {len(blocked_filenames)} filenames")
            return blocked_hashes, blocked_signers, blocked_filenames
        
        def analyze_drivers(blocked_hashes, blocked_signers, blocked_filenames):
            """Analyze drivers against HVCI policy"""
            
            # Load local drivers data
            drv_path = Path('data/drv.json')
            if not drv_path.exists():
                drv_path = Path('data/drvj.json')
            
            with open(drv_path, 'r') as f:
                drivers = json.load(f)
            
            results = []
            
            for driver in drivers:
                if not driver.get('KnownVulnerableSamples'):
                    continue
                    
                for sample in driver['KnownVulnerableSamples']:
                    # Check hashes
                    is_blocked = False
                    block_reason = "Allowed by HVCI"
                    matched_detail = "N/A"
                    
                    # Check all hash types
                    for hash_field in ['MD5', 'SHA1', 'SHA256']:
                        if sample.get(hash_field):
                            clean_hash = sample[hash_field].upper()
                            if clean_hash in blocked_hashes:
                                is_blocked = True
                                block_reason = f"Hash blocked ({hash_field})"
                                matched_detail = clean_hash
                                break
                    
                    # Check Authentihash if not blocked by standard hash
                    if not is_blocked and sample.get('Authentihash'):
                        for hash_field in ['MD5', 'SHA1', 'SHA256']:
                            auth_hash = sample['Authentihash'].get(hash_field)
                            if auth_hash:
                                clean_hash = auth_hash.upper()
                                if clean_hash in blocked_hashes:
                                    is_blocked = True
                                    block_reason = f"Authentihash blocked ({hash_field})"
                                    matched_detail = clean_hash
                                    break
                    
                    # Check filename/tags
                    if not is_blocked and sample.get('Tags'):
                        for tag in sample['Tags']:
                            if tag in blocked_filenames:
                                is_blocked = True
                                block_reason = "Filename blocked"
                                matched_detail = tag
                                break
                    
                    # Certificate validation (simplified)
                    cert_status = "Unknown"
                    signatures = sample.get('Signatures')
                    if signatures:
                        # Handle both dict and list formats
                        if isinstance(signatures, dict) and signatures.get('Certificates'):
                            cert_status = "Valid"
                        elif isinstance(signatures, list) and len(signatures) > 0:
                            # Check if any signature has certificates
                            for sig in signatures:
                                if isinstance(sig, dict) and sig.get('Certificates'):
                                    cert_status = "Valid"
                                    break
                    
                    results.append({
                        'MD5': sample.get('MD5', 'N/A'),
                        'SHA1': sample.get('SHA1', 'N/A'),
                        'SHA256': sample.get('SHA256', 'N/A'),
                        'Status': 'Blocked' if is_blocked else 'Allowed',
                        'BlockReason': block_reason,
                        'MatchedDetail': matched_detail,
                        'CertificateStatus': cert_status,
                        'DriverId': driver.get('Id', 'Unknown'),
                        'Company': sample.get('Company', 'Unknown'),
                        'Filename': sample.get('Filename', sample.get('OriginalFilename', 'Unknown')),
                        'FileVersion': sample.get('FileVersion', 'Unknown')
                    })
            
            return results
        
        def main():
            print("Starting HVCI analysis...")
            
            # Extract and parse policy
            xml_file = extract_blocklist()
            blocked_hashes, blocked_signers, blocked_filenames = parse_hvci_policy(xml_file)
            
            # Analyze drivers
            results = analyze_drivers(blocked_hashes, blocked_signers, blocked_filenames)
            
            # Save results
            with open('hvci_results.csv', 'w', newline='') as f:
                if results:
                    writer = csv.DictWriter(f, fieldnames=results[0].keys())
                    writer.writeheader()
                    writer.writerows(results)
            
            blocked_count = sum(1 for r in results if r['Status'] == 'Blocked')
            print(f"Analysis complete: {len(results)} drivers, {blocked_count} blocked")
            
            # Create summary
            summary = {
                'total_drivers': len(results),
                'blocked_drivers': blocked_count,
                'allowed_drivers': len(results) - blocked_count,
                'policy_components': {
                    'blocked_hashes': len(blocked_hashes),
                    'blocked_signers': len(blocked_signers),
                    'blocked_filenames': len(blocked_filenames)
                }
            }
            
            with open('hvci_summary.json', 'w') as f:
                json.dump(summary, f, indent=2)
        
        if __name__ == '__main__':
            main()
        EOF
        
        python analyze_hvci.py
        
    - name: Upload analysis results
      uses: actions/upload-artifact@v4
      with:
        name: hvci-analysis
        path: |
          hvci_results.csv
          hvci_summary.json

  update_certificates:
    runs-on: ubuntu-latest
    needs: analyze_hvci
    steps:
    - name: Checkout
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Download analysis results
      uses: actions/download-artifact@v4
      with:
        name: hvci-analysis
        
    - name: Update certificate attributes
      run: |
        cat > update_certificates.py << 'EOF'
        #!/usr/bin/env python3
        import json
        import csv
        from pathlib import Path
        
        def load_analysis_results():
            """Load HVCI analysis results"""
            results = {}
            with open('hvci_results.csv', 'r') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    # Map by hash
                    for hash_field in ['MD5', 'SHA1', 'SHA256']:
                        hash_value = row.get(hash_field)
                        if hash_value and hash_value != 'N/A':
                            results[hash_value.upper()] = {
                                'status': row['CertificateStatus'],
                                'hvci_status': row['Status']
                            }
            return results
        
        def update_driver_data(analysis_results):
            """Update driver data with certificate attributes"""
            
            # Load driver data
            drv_path = Path('data/drv.json')
            if not drv_path.exists():
                drv_path = Path('data/drvj.json')
                
            with open(drv_path, 'r') as f:
                drivers = json.load(f)
            
            updated_count = 0
            
            for driver in drivers:
                if not driver.get('KnownVulnerableSamples'):
                    continue
                    
                for sample in driver['KnownVulnerableSamples']:
                    # Find matching analysis result
                    result = None
                    for hash_field in ['MD5', 'SHA1', 'SHA256']:
                        hash_value = sample.get(hash_field)
                        if hash_value and hash_value.upper() in analysis_results:
                            result = analysis_results[hash_value.upper()]
                            break
                    
                    if result:
                        # Add certificate attributes
                        sample['CertificateStatus'] = result['status']
                        sample['HVCIStatus'] = result['hvci_status']
                        
                        # Add individual certificate flags for filtering
                        if result['status'] == 'Valid':
                            sample['CertificateValid'] = True
                        elif result['status'] == 'Expired':
                            sample['CertificateExpired'] = True
                        elif result['status'] == 'Revoked':
                            sample['CertificateRevoked'] = True
                        else:
                            sample['CertificateSuspicious'] = True
                            
                        updated_count += 1
            
            # Save updated data
            with open(drv_path, 'w') as f:
                json.dump(drivers, f, indent=2)
                
            print(f"Updated {updated_count} driver samples with certificate attributes")
            return updated_count
        
        def main():
            print("Loading analysis results...")
            analysis_results = load_analysis_results()
            
            print("Updating driver database...")
            updated_count = update_driver_data(analysis_results)
            
            print(f"Certificate update complete: {updated_count} samples updated")
        
        if __name__ == '__main__':
            main()
        EOF
        
        python update_certificates.py
        
    - name: Upload updated driver data
      uses: actions/upload-artifact@v4
      with:
        name: updated-drv-json
        path: data/drv.json

  commit_changes:
    runs-on: ubuntu-latest
    needs: [download_blocklist, update_certificates]
    if: needs.download_blocklist.outputs.hash_changed == 'true'
    steps:
    - name: Checkout
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Download blocklist and hash
      uses: actions/download-artifact@v4
      with:
        name: blocklist
        
    - name: Download updated driver data
      uses: actions/download-artifact@v4
      with:
        name: updated-drv-json
        path: data/
        
    - name: Restore hash file
      run: |
        # The hash file comes from the blocklist artifact
        if [ -f "data/blocklist-hash.txt" ]; then
          echo "Hash file found in artifact"
          cat data/blocklist-hash.txt
        else
          echo "ERROR: Hash file not found in artifact"
          exit 1
        fi
        
    - name: Commit and push changes
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        # Add files
        git add data/drv.json data/blocklist-hash.txt
        
        # Check if there are changes
        if git diff --staged --quiet; then
          echo "No changes to commit"
          exit 0
        fi
        
        # Commit changes
        git commit -m "🔒 Update HVCI and certificate validation data
        
        - Updated certificate validation attributes
        - Updated HVCI blocklist hash
        - Source: Microsoft Official Vulnerable Driver Blocklist
        - Date: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
        
        git push
        echo "Changes committed and pushed successfully"

  create_summary:
    runs-on: ubuntu-latest
    needs: [analyze_hvci, commit_changes]
    if: always() && needs.analyze_hvci.result == 'success'
    steps:
    - name: Download analysis results
      uses: actions/download-artifact@v4
      with:
        name: hvci-analysis
        
    - name: Create workflow summary
      run: |
        if [ -f "hvci_summary.json" ]; then
          python3 << 'EOF'
        import json
        
        with open('hvci_summary.json', 'r') as f:
            summary = json.load(f)
        
        print("## 🔒 HVCI Analysis Results")
        print("")
        print(f"**Total Drivers Analyzed:** {summary['total_drivers']:,}")
        print(f"**Blocked by HVCI:** {summary['blocked_drivers']:,}")
        print(f"**Allowed by HVCI:** {summary['allowed_drivers']:,}")
        print(f"**Block Rate:** {(summary['blocked_drivers']/summary['total_drivers']*100):.1f}%")
        print("")
        print("### Policy Components")
        components = summary['policy_components']
        print(f"- **Blocked Hashes:** {components['blocked_hashes']:,}")
        print(f"- **Blocked Signers:** {components['blocked_signers']:,}")
        print(f"- **Blocked Filenames:** {components['blocked_filenames']:,}")
        print("")
        print("*Source: Microsoft Official Vulnerable Driver Blocklist*")
        EOF
        else
          echo "## ⚠️ Analysis Summary Not Available"
          echo "The HVCI analysis may have failed or been skipped."
        fi >> $GITHUB_STEP_SUMMARY
